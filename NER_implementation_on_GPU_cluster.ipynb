{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "defcda7a-b85f-4912-b43a-fd1afc16a044",
   "metadata": {},
   "source": [
    "Taken from:\n",
    "https://keras.io/examples/nlp/ner_transformers/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "545b2733-edad-413e-8ba6-11d8852677d9",
   "metadata": {},
   "source": [
    "Introduction\n",
    "\n",
    "Named Entity Recognition (NER) is the process of identifying named entities in text. Example of named entities are: \"Person\", \"Location\", \"Organization\", \"Dates\" etc. NER is essentially a token classification task where every token is classified into one or more predetermined categories.\n",
    "\n",
    "In this exercise, we will train a simple Transformer based model to perform NER. We will be using the data from CoNLL 2003 shared task. For more information about the dataset, please visit the dataset website (https://www.clips.uantwerpen.be/conll2003/ner/). However, since obtaining this data requires an additional step of getting a free license, we will be using HuggingFace's datasets library which contains a processed version of this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec5286c8-9714-4172-8ee9-ad58edcdffe8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip3 install datasets\n",
    "# !wget https://raw.githubusercontent.com/sighsmile/conlleval/master/conlleval.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c91238a-dd6f-4bc6-b52c-98e9aee72b45",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-23 09:30:36.893308: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-10-23 09:30:36.893336: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-10-23 09:30:36.893357: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-10-23 09:30:36.898758: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-10-23 09:30:37.577843: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 121 Âµs (started: 2023-10-23 09:30:38 -04:00)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/miniconda3/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "tf.load_library(\"/etc/alternatives/libcudnn_so\")\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
    "from datasets import load_dataset\n",
    "from collections import Counter\n",
    "from conlleval import evaluate\n",
    "%load_ext autotime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b60f76b6-94ed-440e-b0c3-f3c1dbe1d9f0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-23 09:30:38.435446: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-10-23 09:30:38.435633: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-10-23 09:30:38.456541: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-10-23 09:30:38.456739: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-10-23 09:30:38.456895: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-10-23 09:30:38.457044: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-10-23 09:30:38.581173: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-10-23 09:30:38.581362: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-10-23 09:30:38.581556: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-10-23 09:30:38.581698: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of devices: 2\n",
      "time: 1 s (started: 2023-10-23 09:30:38 -04:00)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-10-23 09:30:38.581838: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-10-23 09:30:38.581977: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-10-23 09:30:39.305759: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-10-23 09:30:39.305960: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-10-23 09:30:39.306109: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-10-23 09:30:39.306247: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-10-23 09:30:39.306388: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-10-23 09:30:39.306510: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3724 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2060, pci bus id: 0000:01:00.0, compute capability: 7.5\n",
      "2023-10-23 09:30:39.306757: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-10-23 09:30:39.306869: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 4607 MB memory:  -> device: 1, name: NVIDIA GeForce RTX 2060, pci bus id: 0000:02:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "# strategy = tf.distribute.MirroredStrategy()\n",
    "\n",
    "# print('Number of devices: {}'.format(strategy.num_replicas_in_sync))\n",
    "\n",
    "\n",
    "# Define your TensorFlow cluster configuration.\n",
    "# Replace this with your actual cluster configuration.\n",
    "cluster_spec = {\n",
    "    \"worker\": [\"worker1:port\", \"worker2:port\"],\n",
    "    \"chief\": [\"chief1:port\"]\n",
    "}\n",
    "\n",
    "cluster_resolver = tf.distribute.cluster_resolver.TFConfigClusterResolver(cluster_spec)\n",
    "\n",
    "# Create a MultiWorkerMirroredStrategy\n",
    "strategy = tf.distribute.experimental.MultiWorkerMirroredStrategy(\n",
    "    communication=tf.distribute.experimental.CollectiveCommunication.AUTO,\n",
    "    cluster_resolver=cluster_resolver\n",
    ")\n",
    "\n",
    "print('Number of devices: {}'.format(strategy.num_replicas_in_sync))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f9b06b2b-2bc5-4161-bba8-1b4120def15f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 268 Âµs (started: 2023-10-23 09:30:39 -04:00)\n"
     ]
    }
   ],
   "source": [
    "train = 'Y'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e605b9d6-19b6-461c-a722-3aacaaaf74c3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.24 ms (started: 2023-10-23 09:30:39 -04:00)\n"
     ]
    }
   ],
   "source": [
    "class TransformerBlock(layers.Layer):\n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1):\n",
    "        super().__init__()\n",
    "        self.att = keras.layers.MultiHeadAttention(\n",
    "            num_heads=num_heads, key_dim=embed_dim\n",
    "        )\n",
    "        self.ffn = keras.Sequential(\n",
    "            [\n",
    "                keras.layers.Dense(ff_dim, activation=\"relu\"),\n",
    "                keras.layers.Dense(embed_dim),\n",
    "            ]\n",
    "        )\n",
    "        self.layernorm1 = keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout1 = keras.layers.Dropout(rate)\n",
    "        self.dropout2 = keras.layers.Dropout(rate)\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        attn_output = self.att(inputs, inputs)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = self.layernorm1(inputs + attn_output)\n",
    "        ffn_output = self.ffn(out1)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        return self.layernorm2(out1 + ffn_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "323e6573-cdb4-4b58-be56-8e36101c061c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 3.55 ms (started: 2023-10-23 09:30:39 -04:00)\n"
     ]
    }
   ],
   "source": [
    "class TokenAndPositionEmbedding(layers.Layer):\n",
    "    def __init__(self, maxlen, vocab_size, embed_dim):\n",
    "        super().__init__()\n",
    "        self.token_emb = keras.layers.Embedding(\n",
    "            input_dim=vocab_size, output_dim=embed_dim\n",
    "        )\n",
    "        self.pos_emb = keras.layers.Embedding(input_dim=maxlen, output_dim=embed_dim)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        maxlen = tf.shape(inputs)[-1]\n",
    "        positions = tf.range(start=0, limit=maxlen, delta=1)\n",
    "        position_embeddings = self.pos_emb(positions)\n",
    "        token_embeddings = self.token_emb(inputs)\n",
    "        return token_embeddings + position_embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a06d64-b3dd-441e-9c23-68214e66f99d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ae2adca4-a399-44cd-a389-a1979befd024",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.66 ms (started: 2023-10-23 09:30:39 -04:00)\n"
     ]
    }
   ],
   "source": [
    "class NERModel(keras.Model):\n",
    "    def __init__(\n",
    "        self, num_tags, vocab_size, maxlen=128, embed_dim=32, num_heads=2, ff_dim=32\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.embedding_layer = TokenAndPositionEmbedding(maxlen, vocab_size, embed_dim)\n",
    "        self.transformer_block = TransformerBlock(embed_dim, num_heads, ff_dim)\n",
    "        self.dropout1 = layers.Dropout(0.1)\n",
    "        self.ff = layers.Dense(ff_dim, activation=\"relu\")\n",
    "        self.dropout2 = layers.Dropout(0.1)\n",
    "        self.ff_final = layers.Dense(num_tags, activation=\"softmax\")\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        x = self.embedding_layer(inputs)\n",
    "        x = self.transformer_block(x)\n",
    "        x = self.dropout1(x, training=training)\n",
    "        x = self.ff(x)\n",
    "        x = self.dropout2(x, training=training)\n",
    "        x = self.ff_final(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8d6bb598-55bf-484c-a84b-c858c8da3800",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 5.77 s (started: 2023-10-23 09:30:39 -04:00)\n"
     ]
    }
   ],
   "source": [
    "conll_data = load_dataset(\"conll2003\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f2a66b2d-54b0-4a35-bec3-3e976516b6fc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 793 ms (started: 2023-10-23 09:30:45 -04:00)\n"
     ]
    }
   ],
   "source": [
    "def export_to_file_examine(export_file_path, data):\n",
    "    with open(export_file_path, \"w\") as f:\n",
    "        for record in data:\n",
    "            tokens = record[\"tokens\"]\n",
    "            if len(tokens) > 0:\n",
    "                f.write(\n",
    "                    \" \".join(tokens)\n",
    "                    + \"\\n\"\n",
    "                )\n",
    "\n",
    "# os.mkdir(\"data\")\n",
    "export_to_file_examine(\"./data/conll_examine.txt\", conll_data[\"train\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "25b4a804-ae07-4053-8145-4e80ebc46675",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 328 Âµs (started: 2023-10-23 09:30:46 -04:00)\n"
     ]
    }
   ],
   "source": [
    "# def export_to_file(export_file_path, data):\n",
    "#     with open(export_file_path, \"w\") as f:\n",
    "#         for record in data:\n",
    "#             ner_tags = record[\"ner_tags\"]\n",
    "#             tokens = record[\"tokens\"]\n",
    "#             if len(tokens) > 0:\n",
    "#                 f.write(\n",
    "#                     str(len(tokens))\n",
    "#                     + \"\\t\"\n",
    "#                     + \"\\t\".join(tokens)\n",
    "#                     + \"\\t\"\n",
    "#                     + \"\\t\".join(map(str, ner_tags))\n",
    "#                     + \"\\n\"\n",
    "#                 )\n",
    "\n",
    "\n",
    "# # os.mkdir(\"data\")\n",
    "# export_to_file(\"./data/conll_train.txt\", conll_data[\"train\"])\n",
    "# export_to_file(\"./data/conll_val.txt\", conll_data[\"validation\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e612db4c-8c0c-4fdb-8956-b0c3aed54eaa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.01 s (started: 2023-10-23 09:30:46 -04:00)\n"
     ]
    }
   ],
   "source": [
    "def export_to_file(export_file_path, data):\n",
    "    with open(export_file_path, \"w\") as f:\n",
    "        for record in data:\n",
    "            ner_tags = record[\"ner_tags\"]\n",
    "            tokens = record[\"tokens\"]\n",
    "            if len(tokens) > 0:\n",
    "                binary_tags = per_tags(ner_tags)\n",
    "                f.write(\n",
    "                    str(len(tokens))\n",
    "                    + \"\\t\"\n",
    "                    + \"\\t\".join(tokens)\n",
    "                    + \"\\t\"\n",
    "                    + \"\\t\".join(map(str, binary_tags))\n",
    "                    + \"\\n\"\n",
    "                )\n",
    "\n",
    "def per_tags(nertags):\n",
    "    return [1 if x in (1,2) else 0 for x in nertags]\n",
    "\n",
    "# Uncomment this if you want to create the directory\n",
    "# os.mkdir(\"data\")\n",
    "export_to_file(\"./data/conll_train.txt\", conll_data[\"train\"])\n",
    "export_to_file(\"./data/conll_val.txt\", conll_data[\"validation\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "499f5057-3b81-4999-ae4b-a31895471f53",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: '[PAD]', 1: 'O', 2: 'B-PER', 3: 'I-PER', 4: 'B-ORG', 5: 'I-ORG', 6: 'B-LOC', 7: 'I-LOC', 8: 'B-MISC', 9: 'I-MISC'}\n",
      "time: 657 Âµs (started: 2023-10-23 09:30:47 -04:00)\n"
     ]
    }
   ],
   "source": [
    "def make_tag_lookup_table():\n",
    "    iob_labels = [\"B\", \"I\"]\n",
    "    ner_labels = [\"PER\", \"ORG\", \"LOC\", \"MISC\"]\n",
    "    all_labels = [(label1, label2) for label2 in ner_labels for label1 in iob_labels]\n",
    "    all_labels = [\"-\".join([a, b]) for a, b in all_labels]\n",
    "    all_labels = [\"[PAD]\", \"O\"] + all_labels\n",
    "    return dict(zip(range(0, len(all_labels) + 1), all_labels))\n",
    "\n",
    "\n",
    "mapping = make_tag_lookup_table()\n",
    "print(mapping)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1c2cabe2-b667-4d51-b50f-3824f6fed563",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21009\n",
      "time: 5.75 s (started: 2023-10-23 09:30:47 -04:00)\n"
     ]
    }
   ],
   "source": [
    "all_tokens = sum(conll_data[\"train\"][\"tokens\"], [])\n",
    "all_tokens_array = np.array(list(map(str.lower, all_tokens)))\n",
    "\n",
    "counter = Counter(all_tokens_array)\n",
    "print(len(counter))\n",
    "\n",
    "num_tags = len(mapping)\n",
    "vocab_size = 20000\n",
    "\n",
    "# We only take (vocab_size - 2) most commons words from the training data since\n",
    "# the `StringLookup` class uses 2 additional tokens - one denoting an unknown\n",
    "# token and another one denoting a masking token\n",
    "vocabulary = [token for token, count in counter.most_common(vocab_size - 2)]\n",
    "\n",
    "# The StringLook class will convert tokens to token IDs\n",
    "lookup_layer = keras.layers.StringLookup(\n",
    "    vocabulary=vocabulary\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b9aec221-080b-4452-aed7-f72e04df2e35",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 14.5 ms (started: 2023-10-23 09:30:52 -04:00)\n"
     ]
    }
   ],
   "source": [
    "train_data = tf.data.TextLineDataset(\"./data/conll_train.txt\")\n",
    "val_data = tf.data.TextLineDataset(\"./data/conll_val.txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "542bf15c-2605-43f8-84b9-edf5f2c2c4c6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[b'9\\tEU\\trejects\\tGerman\\tcall\\tto\\tboycott\\tBritish\\tlamb\\t.\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0']\n",
      "time: 42 ms (started: 2023-10-23 09:30:52 -04:00)\n"
     ]
    }
   ],
   "source": [
    "print(list(train_data.take(1).as_numpy_iterator()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c1cc8d8f-8d13-4db9-a26d-c65cc889cf18",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 166 ms (started: 2023-10-23 09:30:52 -04:00)\n"
     ]
    }
   ],
   "source": [
    "def map_record_to_training_data(record):\n",
    "    record = tf.strings.split(record, sep=\"\\t\")\n",
    "    length = tf.strings.to_number(record[0], out_type=tf.int32)\n",
    "    tokens = record[1 : length + 1]\n",
    "    tags = record[length + 1 :]\n",
    "    tags = tf.strings.to_number(tags, out_type=tf.int64)\n",
    "    tags += 1\n",
    "    return tokens, tags\n",
    "\n",
    "\n",
    "def lowercase_and_convert_to_ids(tokens):\n",
    "    tokens = tf.strings.lower(tokens)\n",
    "    return lookup_layer(tokens)\n",
    "\n",
    "\n",
    "# We use `padded_batch` here because each record in the dataset has a\n",
    "# different length.\n",
    "batch_size = 32\n",
    "train_dataset = (\n",
    "    train_data.map(map_record_to_training_data)\n",
    "    .map(lambda x, y: (lowercase_and_convert_to_ids(x), y))\n",
    "    .padded_batch(batch_size)\n",
    ")\n",
    "val_dataset = (\n",
    "    val_data.map(map_record_to_training_data)\n",
    "    .map(lambda x, y: (lowercase_and_convert_to_ids(x), y))\n",
    "    .padded_batch(batch_size)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "54aeeeef-9e69-4c0e-b355-4351589127c3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 527 Âµs (started: 2023-10-23 09:30:53 -04:00)\n"
     ]
    }
   ],
   "source": [
    "class CustomNonPaddingTokenLoss(keras.losses.Loss):\n",
    "    def __init__(self, name=\"custom_ner_loss\"):\n",
    "        super().__init__(name=name)\n",
    "\n",
    "    def call(self, y_true, y_pred):\n",
    "        loss_fn = keras.losses.SparseCategoricalCrossentropy(\n",
    "            from_logits=False, reduction=keras.losses.Reduction.NONE\n",
    "        )\n",
    "        loss = loss_fn(y_true, y_pred)\n",
    "        mask = tf.cast((y_true > 0), dtype=tf.float32)\n",
    "        loss = loss * mask\n",
    "        return tf.reduce_sum(loss) / tf.reduce_sum(mask)\n",
    "\n",
    "\n",
    "loss = CustomNonPaddingTokenLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "330dafa0-0e94-4ba1-8e1a-82b9cd82593c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 39.5 ms (started: 2023-10-23 09:30:53 -04:00)\n"
     ]
    }
   ],
   "source": [
    "with strategy.scope():\n",
    "    es = EarlyStopping(monitor='val_accuracy', mode='min', verbose=2, patience=5)\n",
    "    ner_model = NERModel(num_tags, vocab_size, embed_dim=32, num_heads=4, ff_dim=64)\n",
    "    history = ner_model.compile(optimizer=\"adam\", loss=loss, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d191bd59-01c0-460d-b167-d12a850475ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-23 09:30:58.778027: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fc6c80cdb50 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-10-23 09:30:58.778051: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 2060, Compute Capability 7.5\n",
      "2023-10-23 09:30:58.778058: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (1): NVIDIA GeForce RTX 2060, Compute Capability 7.5\n",
      "2023-10-23 09:30:58.785177: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-10-23 09:30:58.910531: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:442] Loaded cuDNN version 8700\n",
      "2023-10-23 09:30:58.979867: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "2023-10-23 09:30:59.007557: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:442] Loaded cuDNN version 8700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "439/439 [==============================] - 38s 72ms/step - loss: 0.2156 - accuracy: 0.3871\n",
      "Epoch 2/500\n",
      "  1/439 [..............................] - ETA: 5s - loss: 0.0973 - accuracy: 0.4781"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-23 09:31:31.490874: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 13653882349482229730\n",
      "2023-10-23 09:31:31.490929: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 10078033694558757461\n",
      "2023-10-23 09:31:31.490935: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 10024542798458750951\n",
      "2023-10-23 09:31:31.490940: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 1310130686640892034\n",
      "2023-10-23 09:31:31.490945: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 8051083902128466386\n",
      "2023-10-23 09:31:31.490949: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 4512108454896405146\n",
      "2023-10-23 09:31:31.490953: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 2892971597650856534\n",
      "2023-10-23 09:31:31.490961: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 9097674255635334108\n",
      "2023-10-23 09:31:31.490988: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 10950168553240994955\n",
      "2023-10-23 09:31:31.490997: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 3260041222566602154\n",
      "2023-10-23 09:31:31.491005: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 12254149556074407186\n",
      "2023-10-23 09:31:31.491016: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 18105730374859458821\n",
      "2023-10-23 09:31:31.491055: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 9218823273710757618\n",
      "2023-10-23 09:31:31.491068: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 8571909193162533536\n",
      "2023-10-23 09:31:31.491086: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 8860357921679305752\n",
      "2023-10-23 09:31:31.491094: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 3299660462435348087\n",
      "2023-10-23 09:31:31.491115: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 5887388098883416332\n",
      "2023-10-23 09:31:31.491123: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 5702144126651953181\n",
      "2023-10-23 09:31:31.491131: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 11133247904677483125\n",
      "2023-10-23 09:31:31.491152: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 805925624869916678\n",
      "2023-10-23 09:31:31.491158: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 9762524824737223632\n",
      "2023-10-23 09:31:31.491167: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 13065849031912519532\n",
      "2023-10-23 09:31:31.491175: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 3888882474858402939\n",
      "2023-10-23 09:31:31.491183: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 17940127402731449081\n",
      "2023-10-23 09:31:31.491189: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 12831074921196786852\n",
      "2023-10-23 09:31:31.491197: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 1292022415519268858\n",
      "2023-10-23 09:31:31.491204: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 16496572869128730510\n",
      "2023-10-23 09:31:31.491218: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 15163154911370872237\n",
      "2023-10-23 09:31:31.491224: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 7322991101961001353\n",
      "2023-10-23 09:31:31.491233: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 6109792216203298411\n",
      "2023-10-23 09:31:31.491240: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 12521084792004114909\n",
      "2023-10-23 09:31:31.491249: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 15271407011965961932\n",
      "2023-10-23 09:31:31.491253: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 3940935947011603206\n",
      "2023-10-23 09:31:31.491262: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 7843513565358442354\n",
      "2023-10-23 09:31:31.491266: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 2287791985001405727\n",
      "2023-10-23 09:31:31.491275: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 16387708260239706127\n",
      "2023-10-23 09:31:31.491285: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 8634478274143903359\n",
      "2023-10-23 09:31:31.491295: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 6288370663870270345\n",
      "2023-10-23 09:31:31.491304: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 18315506707946626680\n",
      "2023-10-23 09:31:31.491314: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 15145294696373390338\n",
      "2023-10-23 09:31:31.491322: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 2535571613811856279\n",
      "2023-10-23 09:31:31.491327: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 17519788647573854050\n",
      "2023-10-23 09:31:31.491332: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 10141383021114808099\n",
      "2023-10-23 09:31:31.491337: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 9164916985243621825\n",
      "2023-10-23 09:31:31.491341: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 8925494255905332844\n",
      "2023-10-23 09:31:31.491347: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 3180463457426874601\n",
      "2023-10-23 09:31:31.491353: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 16638555877674297355\n",
      "2023-10-23 09:31:31.491361: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 1027259881225218871\n",
      "2023-10-23 09:31:31.491370: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 4008314983336553326\n",
      "2023-10-23 09:31:31.491379: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 15290738325100981675\n",
      "2023-10-23 09:31:31.491389: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 10009888132733185906\n",
      "2023-10-23 09:31:31.491398: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 16705584620463779674\n",
      "2023-10-23 09:31:31.491408: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 3227406948826903054\n",
      "2023-10-23 09:31:31.491417: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 15809383293891982222\n",
      "2023-10-23 09:31:31.491427: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 1942751740846191925\n",
      "2023-10-23 09:31:31.491435: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 5351097636065769424\n",
      "2023-10-23 09:31:31.491442: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 2258968017901926385\n",
      "2023-10-23 09:31:31.491449: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 12216564803652745654\n",
      "2023-10-23 09:31:31.491461: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 9896375144662825612\n",
      "2023-10-23 09:31:31.491480: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 13816163595358518448\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "439/439 [==============================] - 5s 11ms/step - loss: 0.0405 - accuracy: 0.4041\n",
      "Epoch 3/500\n",
      "439/439 [==============================] - 5s 11ms/step - loss: 0.0137 - accuracy: 0.4073\n",
      "Epoch 4/500\n",
      "439/439 [==============================] - 5s 11ms/step - loss: 0.0085 - accuracy: 0.4078\n",
      "Epoch 5/500\n",
      "439/439 [==============================] - 5s 11ms/step - loss: 0.0061 - accuracy: 0.4082\n",
      "Epoch 6/500\n",
      "439/439 [==============================] - 5s 11ms/step - loss: 0.0067 - accuracy: 0.4080\n",
      "Epoch 7/500\n",
      "439/439 [==============================] - 5s 11ms/step - loss: 0.0048 - accuracy: 0.4083\n",
      "Epoch 8/500\n",
      "439/439 [==============================] - 5s 11ms/step - loss: 0.0036 - accuracy: 0.4085\n",
      "Epoch 9/500\n",
      "439/439 [==============================] - 5s 11ms/step - loss: 0.0029 - accuracy: 0.4085\n",
      "Epoch 10/500\n",
      "439/439 [==============================] - 5s 11ms/step - loss: 0.0031 - accuracy: 0.4085\n",
      "Epoch 11/500\n",
      "439/439 [==============================] - 5s 11ms/step - loss: 0.0027 - accuracy: 0.4086\n",
      "Epoch 12/500\n",
      "439/439 [==============================] - 5s 11ms/step - loss: 0.0020 - accuracy: 0.4087\n",
      "Epoch 13/500\n",
      "439/439 [==============================] - 5s 11ms/step - loss: 0.0015 - accuracy: 0.4088\n",
      "Epoch 14/500\n",
      "439/439 [==============================] - 5s 11ms/step - loss: 0.0022 - accuracy: 0.4087\n",
      "Epoch 15/500\n",
      "439/439 [==============================] - 5s 11ms/step - loss: 0.0017 - accuracy: 0.4087\n",
      "Epoch 16/500\n",
      "439/439 [==============================] - 5s 11ms/step - loss: 0.0017 - accuracy: 0.4088\n",
      "Epoch 17/500\n",
      "439/439 [==============================] - 5s 11ms/step - loss: 0.0012 - accuracy: 0.4088\n",
      "Epoch 18/500\n",
      "439/439 [==============================] - 5s 11ms/step - loss: 7.6280e-04 - accuracy: 0.4089\n",
      "Epoch 19/500\n",
      "439/439 [==============================] - 5s 11ms/step - loss: 0.0011 - accuracy: 0.4088\n",
      "Epoch 20/500\n",
      "439/439 [==============================] - 5s 11ms/step - loss: 0.0011 - accuracy: 0.4088\n",
      "Epoch 21/500\n",
      "439/439 [==============================] - 5s 11ms/step - loss: 8.7625e-04 - accuracy: 0.4089\n",
      "Epoch 22/500\n",
      "439/439 [==============================] - 5s 11ms/step - loss: 0.0010 - accuracy: 0.4088\n",
      "Epoch 23/500\n",
      "439/439 [==============================] - 5s 11ms/step - loss: 8.7862e-04 - accuracy: 0.4088\n",
      "Epoch 24/500\n",
      "439/439 [==============================] - 5s 11ms/step - loss: 8.6878e-04 - accuracy: 0.4089\n",
      "Epoch 25/500\n",
      "439/439 [==============================] - 5s 11ms/step - loss: 4.8247e-04 - accuracy: 0.4089\n",
      "Epoch 26/500\n",
      "439/439 [==============================] - 5s 11ms/step - loss: 5.0446e-04 - accuracy: 0.4089\n",
      "Epoch 27/500\n",
      "439/439 [==============================] - 5s 11ms/step - loss: 0.0011 - accuracy: 0.4088\n",
      "Epoch 28/500\n",
      "439/439 [==============================] - 5s 11ms/step - loss: 5.6201e-04 - accuracy: 0.4089\n",
      "Epoch 29/500\n",
      "439/439 [==============================] - 5s 11ms/step - loss: 2.9295e-04 - accuracy: 0.4089\n",
      "Epoch 30/500\n",
      "439/439 [==============================] - 5s 11ms/step - loss: 3.9447e-04 - accuracy: 0.4089\n",
      "Epoch 31/500\n",
      "439/439 [==============================] - 5s 11ms/step - loss: 7.5103e-04 - accuracy: 0.4089\n",
      "Epoch 32/500\n",
      "439/439 [==============================] - 5s 11ms/step - loss: 0.0010 - accuracy: 0.4088\n",
      "Epoch 33/500\n",
      "439/439 [==============================] - 5s 11ms/step - loss: 7.7111e-04 - accuracy: 0.4089\n",
      "Epoch 34/500\n",
      "439/439 [==============================] - 5s 11ms/step - loss: 4.9475e-04 - accuracy: 0.4089\n",
      "Epoch 35/500\n",
      "439/439 [==============================] - 5s 11ms/step - loss: 2.6666e-04 - accuracy: 0.4089\n",
      "Epoch 36/500\n",
      "439/439 [==============================] - 5s 11ms/step - loss: 1.6263e-04 - accuracy: 0.4090\n",
      "Epoch 37/500\n",
      "439/439 [==============================] - 5s 11ms/step - loss: 2.9374e-04 - accuracy: 0.4089\n",
      "Epoch 38/500\n",
      "439/439 [==============================] - 5s 11ms/step - loss: 3.9784e-04 - accuracy: 0.4089\n",
      "Epoch 39/500\n",
      "439/439 [==============================] - 5s 11ms/step - loss: 2.6823e-04 - accuracy: 0.4089\n",
      "Epoch 40/500\n",
      "439/439 [==============================] - 5s 11ms/step - loss: 7.6849e-04 - accuracy: 0.4089\n",
      "Epoch 41/500\n",
      "439/439 [==============================] - 5s 11ms/step - loss: 4.2783e-04 - accuracy: 0.4089\n",
      "Epoch 42/500\n",
      "439/439 [==============================] - 5s 11ms/step - loss: 3.1861e-04 - accuracy: 0.4089\n",
      "Epoch 43/500\n",
      "439/439 [==============================] - 5s 11ms/step - loss: 2.6668e-04 - accuracy: 0.4089\n",
      "Epoch 44/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 3.9633e-04 - accuracy: 0.4089\n",
      "Epoch 45/500\n",
      "439/439 [==============================] - 5s 11ms/step - loss: 7.4959e-04 - accuracy: 0.4089\n",
      "Epoch 46/500\n",
      "439/439 [==============================] - 5s 11ms/step - loss: 1.9201e-04 - accuracy: 0.4090\n",
      "Epoch 47/500\n",
      "439/439 [==============================] - 5s 11ms/step - loss: 3.0581e-04 - accuracy: 0.4090\n",
      "Epoch 48/500\n",
      "439/439 [==============================] - 5s 11ms/step - loss: 4.5152e-04 - accuracy: 0.4089\n",
      "Epoch 49/500\n",
      "439/439 [==============================] - 5s 11ms/step - loss: 0.0012 - accuracy: 0.4089\n",
      "Epoch 50/500\n",
      "439/439 [==============================] - 5s 11ms/step - loss: 5.2119e-04 - accuracy: 0.4089\n",
      "Epoch 51/500\n",
      "439/439 [==============================] - 5s 11ms/step - loss: 2.0923e-04 - accuracy: 0.4090\n",
      "Epoch 52/500\n",
      "439/439 [==============================] - 5s 11ms/step - loss: 1.0710e-04 - accuracy: 0.4090\n",
      "Epoch 53/500\n",
      "439/439 [==============================] - 5s 11ms/step - loss: 9.0034e-05 - accuracy: 0.4090\n",
      "Epoch 54/500\n",
      "439/439 [==============================] - 5s 11ms/step - loss: 6.1635e-05 - accuracy: 0.4090\n",
      "Epoch 55/500\n",
      "439/439 [==============================] - 5s 11ms/step - loss: 1.5307e-04 - accuracy: 0.4090\n",
      "Epoch 56/500\n",
      "439/439 [==============================] - 5s 11ms/step - loss: 4.2855e-04 - accuracy: 0.4089\n",
      "Epoch 57/500\n",
      "439/439 [==============================] - 5s 11ms/step - loss: 5.0465e-04 - accuracy: 0.4089\n",
      "Epoch 58/500\n",
      "439/439 [==============================] - 5s 11ms/step - loss: 7.7514e-04 - accuracy: 0.4089\n",
      "Epoch 59/500\n",
      "439/439 [==============================] - 5s 11ms/step - loss: 2.5835e-04 - accuracy: 0.4089\n",
      "Epoch 60/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 2.5372e-04 - accuracy: 0.4090\n",
      "Epoch 61/500\n",
      "439/439 [==============================] - 5s 11ms/step - loss: 3.0650e-04 - accuracy: 0.4090\n",
      "Epoch 62/500\n",
      "439/439 [==============================] - 5s 11ms/step - loss: 1.6424e-04 - accuracy: 0.4090\n",
      "Epoch 63/500\n",
      "439/439 [==============================] - 5s 11ms/step - loss: 5.2226e-05 - accuracy: 0.4090\n",
      "Epoch 64/500\n",
      "439/439 [==============================] - 5s 11ms/step - loss: 5.7087e-05 - accuracy: 0.4090\n",
      "Epoch 65/500\n",
      "439/439 [==============================] - 5s 11ms/step - loss: 2.6366e-04 - accuracy: 0.4090\n",
      "Epoch 66/500\n",
      "439/439 [==============================] - 5s 11ms/step - loss: 4.7179e-04 - accuracy: 0.4089\n",
      "Epoch 67/500\n",
      "439/439 [==============================] - 5s 11ms/step - loss: 5.3139e-04 - accuracy: 0.4089\n",
      "Epoch 68/500\n",
      "439/439 [==============================] - 5s 11ms/step - loss: 2.7850e-04 - accuracy: 0.4089\n",
      "Epoch 69/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 1.6500e-04 - accuracy: 0.4090\n",
      "Epoch 70/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 1.4238e-04 - accuracy: 0.4090\n",
      "Epoch 71/500\n",
      "439/439 [==============================] - 5s 11ms/step - loss: 1.2984e-04 - accuracy: 0.4090\n",
      "Epoch 72/500\n",
      "439/439 [==============================] - 5s 11ms/step - loss: 1.3864e-04 - accuracy: 0.4090\n",
      "Epoch 73/500\n",
      "439/439 [==============================] - 5s 11ms/step - loss: 2.4217e-04 - accuracy: 0.4090\n",
      "Epoch 74/500\n",
      "439/439 [==============================] - 5s 11ms/step - loss: 6.2031e-04 - accuracy: 0.4089\n",
      "Epoch 75/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 3.7134e-04 - accuracy: 0.4089\n",
      "Epoch 76/500\n",
      "439/439 [==============================] - 5s 11ms/step - loss: 1.3228e-04 - accuracy: 0.4090\n",
      "Epoch 77/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 1.5357e-04 - accuracy: 0.4090\n",
      "Epoch 78/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 7.2189e-05 - accuracy: 0.4090\n",
      "Epoch 79/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 1.1300e-04 - accuracy: 0.4090\n",
      "Epoch 80/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 7.5466e-05 - accuracy: 0.4090\n",
      "Epoch 81/500\n",
      "439/439 [==============================] - 5s 11ms/step - loss: 6.1958e-05 - accuracy: 0.4090\n",
      "Epoch 82/500\n",
      "439/439 [==============================] - 5s 11ms/step - loss: 1.9179e-04 - accuracy: 0.4090\n",
      "Epoch 83/500\n",
      "439/439 [==============================] - 5s 11ms/step - loss: 1.8220e-04 - accuracy: 0.4090\n",
      "Epoch 84/500\n",
      "439/439 [==============================] - 5s 11ms/step - loss: 3.7257e-04 - accuracy: 0.4089\n",
      "Epoch 85/500\n",
      "439/439 [==============================] - 5s 11ms/step - loss: 2.8477e-04 - accuracy: 0.4090\n",
      "Epoch 86/500\n",
      "439/439 [==============================] - 5s 11ms/step - loss: 5.2573e-04 - accuracy: 0.4089\n",
      "Epoch 87/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 8.9077e-04 - accuracy: 0.4089\n",
      "Epoch 88/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 1.3949e-04 - accuracy: 0.4090\n",
      "Epoch 89/500\n",
      "439/439 [==============================] - 5s 11ms/step - loss: 4.3970e-05 - accuracy: 0.4090\n",
      "Epoch 90/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 2.1868e-05 - accuracy: 0.4090\n",
      "Epoch 91/500\n",
      "439/439 [==============================] - 5s 11ms/step - loss: 4.9319e-05 - accuracy: 0.4090\n",
      "Epoch 92/500\n",
      "439/439 [==============================] - 5s 11ms/step - loss: 2.3487e-05 - accuracy: 0.4090\n",
      "Epoch 93/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 4.0891e-05 - accuracy: 0.4090\n",
      "Epoch 94/500\n",
      "439/439 [==============================] - 5s 11ms/step - loss: 6.0642e-05 - accuracy: 0.4090\n",
      "Epoch 95/500\n",
      "439/439 [==============================] - 5s 11ms/step - loss: 2.2800e-04 - accuracy: 0.4090\n",
      "Epoch 96/500\n",
      "439/439 [==============================] - 5s 11ms/step - loss: 2.2929e-04 - accuracy: 0.4090\n",
      "Epoch 97/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 2.8983e-04 - accuracy: 0.4089\n",
      "Epoch 98/500\n",
      "439/439 [==============================] - 5s 11ms/step - loss: 1.3849e-04 - accuracy: 0.4090\n",
      "Epoch 99/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 2.4271e-04 - accuracy: 0.4090\n",
      "Epoch 100/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 3.9661e-05 - accuracy: 0.4090\n",
      "Epoch 101/500\n",
      "439/439 [==============================] - 5s 11ms/step - loss: 5.0183e-05 - accuracy: 0.4090\n",
      "Epoch 102/500\n",
      "439/439 [==============================] - 5s 11ms/step - loss: 1.7810e-05 - accuracy: 0.4090\n",
      "Epoch 103/500\n",
      "439/439 [==============================] - 5s 11ms/step - loss: 2.3560e-04 - accuracy: 0.4090\n",
      "Epoch 104/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 5.6747e-04 - accuracy: 0.4089\n",
      "Epoch 105/500\n",
      "439/439 [==============================] - 5s 11ms/step - loss: 2.8405e-04 - accuracy: 0.4090\n",
      "Epoch 106/500\n",
      "439/439 [==============================] - 5s 11ms/step - loss: 9.4308e-05 - accuracy: 0.4090\n",
      "Epoch 107/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 3.4759e-05 - accuracy: 0.4090\n",
      "Epoch 108/500\n",
      "439/439 [==============================] - 5s 11ms/step - loss: 5.9542e-05 - accuracy: 0.4090\n",
      "Epoch 109/500\n",
      "439/439 [==============================] - 5s 11ms/step - loss: 1.8256e-04 - accuracy: 0.4090\n",
      "Epoch 110/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 1.2072e-04 - accuracy: 0.4090\n",
      "Epoch 111/500\n",
      "439/439 [==============================] - 5s 11ms/step - loss: 3.2183e-05 - accuracy: 0.4090\n",
      "Epoch 112/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 6.8062e-05 - accuracy: 0.4090\n",
      "Epoch 113/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 7.6723e-05 - accuracy: 0.4090\n",
      "Epoch 114/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 1.2173e-04 - accuracy: 0.4090\n",
      "Epoch 115/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 1.1988e-04 - accuracy: 0.4090\n",
      "Epoch 116/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 2.5452e-04 - accuracy: 0.4090\n",
      "Epoch 117/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 1.5739e-04 - accuracy: 0.4090\n",
      "Epoch 118/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 2.5023e-04 - accuracy: 0.4090\n",
      "Epoch 119/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 1.4540e-04 - accuracy: 0.4090\n",
      "Epoch 120/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 4.0576e-05 - accuracy: 0.4090\n",
      "Epoch 121/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 1.0548e-05 - accuracy: 0.4090\n",
      "Epoch 122/500\n",
      "439/439 [==============================] - 5s 11ms/step - loss: 5.8175e-05 - accuracy: 0.4090\n",
      "Epoch 123/500\n",
      "439/439 [==============================] - 5s 11ms/step - loss: 3.2517e-04 - accuracy: 0.4090\n",
      "Epoch 124/500\n",
      "439/439 [==============================] - 5s 11ms/step - loss: 4.8359e-04 - accuracy: 0.4090\n",
      "Epoch 125/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 2.2824e-04 - accuracy: 0.4090\n",
      "Epoch 126/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 1.0838e-04 - accuracy: 0.4090\n",
      "Epoch 127/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 2.1021e-05 - accuracy: 0.4090\n",
      "Epoch 128/500\n",
      "439/439 [==============================] - 5s 11ms/step - loss: 1.6255e-05 - accuracy: 0.4090\n",
      "Epoch 129/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 7.8977e-06 - accuracy: 0.4090\n",
      "Epoch 130/500\n",
      "439/439 [==============================] - 5s 11ms/step - loss: 7.1644e-06 - accuracy: 0.4090\n",
      "Epoch 131/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 8.2802e-06 - accuracy: 0.4090\n",
      "Epoch 132/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 1.5250e-04 - accuracy: 0.4090\n",
      "Epoch 133/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 3.5759e-04 - accuracy: 0.4089\n",
      "Epoch 134/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 1.6384e-04 - accuracy: 0.4090\n",
      "Epoch 135/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 1.5103e-04 - accuracy: 0.4090\n",
      "Epoch 136/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 1.7105e-05 - accuracy: 0.4090\n",
      "Epoch 137/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 9.8530e-06 - accuracy: 0.4090\n",
      "Epoch 138/500\n",
      "439/439 [==============================] - 5s 11ms/step - loss: 9.0814e-06 - accuracy: 0.4090\n",
      "Epoch 139/500\n",
      "439/439 [==============================] - 5s 11ms/step - loss: 3.1343e-05 - accuracy: 0.4090\n",
      "Epoch 140/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 1.1476e-04 - accuracy: 0.4090\n",
      "Epoch 141/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 1.3822e-04 - accuracy: 0.4090\n",
      "Epoch 142/500\n",
      "439/439 [==============================] - 5s 11ms/step - loss: 3.0158e-04 - accuracy: 0.4090\n",
      "Epoch 143/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 7.4978e-05 - accuracy: 0.4090\n",
      "Epoch 144/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 1.1375e-04 - accuracy: 0.4090\n",
      "Epoch 145/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 8.5655e-05 - accuracy: 0.4090\n",
      "Epoch 146/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 9.8479e-05 - accuracy: 0.4090\n",
      "Epoch 147/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 1.9993e-05 - accuracy: 0.4090\n",
      "Epoch 148/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 1.8963e-05 - accuracy: 0.4090\n",
      "Epoch 149/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 8.3169e-06 - accuracy: 0.4090\n",
      "Epoch 150/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 1.3018e-05 - accuracy: 0.4090\n",
      "Epoch 151/500\n",
      "439/439 [==============================] - 5s 11ms/step - loss: 1.3078e-05 - accuracy: 0.4090\n",
      "Epoch 152/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 1.0392e-05 - accuracy: 0.4090\n",
      "Epoch 153/500\n",
      "439/439 [==============================] - 5s 11ms/step - loss: 2.6620e-05 - accuracy: 0.4090\n",
      "Epoch 154/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 2.3981e-04 - accuracy: 0.4090\n",
      "Epoch 155/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 4.3032e-04 - accuracy: 0.4090\n",
      "Epoch 156/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 2.6335e-04 - accuracy: 0.4090\n",
      "Epoch 157/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 1.0407e-04 - accuracy: 0.4090\n",
      "Epoch 158/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 2.0571e-05 - accuracy: 0.4090\n",
      "Epoch 159/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 1.6588e-05 - accuracy: 0.4090\n",
      "Epoch 160/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 1.4233e-05 - accuracy: 0.4090\n",
      "Epoch 161/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 1.0515e-05 - accuracy: 0.4090\n",
      "Epoch 162/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 3.1894e-05 - accuracy: 0.4090\n",
      "Epoch 163/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 9.8249e-05 - accuracy: 0.4090\n",
      "Epoch 164/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 4.6073e-04 - accuracy: 0.4090\n",
      "Epoch 165/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 1.8532e-04 - accuracy: 0.4090\n",
      "Epoch 166/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 3.5664e-05 - accuracy: 0.4090\n",
      "Epoch 167/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 1.3111e-05 - accuracy: 0.4090\n",
      "Epoch 168/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 8.9695e-06 - accuracy: 0.4090\n",
      "Epoch 169/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 8.3026e-06 - accuracy: 0.4090\n",
      "Epoch 170/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 1.8841e-05 - accuracy: 0.4090\n",
      "Epoch 171/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 9.5622e-06 - accuracy: 0.4090\n",
      "Epoch 172/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 4.0943e-05 - accuracy: 0.4090\n",
      "Epoch 173/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 1.1904e-04 - accuracy: 0.4090\n",
      "Epoch 174/500\n",
      "439/439 [==============================] - 6s 14ms/step - loss: 1.3397e-04 - accuracy: 0.4090\n",
      "Epoch 175/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 2.5355e-04 - accuracy: 0.4090\n",
      "Epoch 176/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 3.5704e-05 - accuracy: 0.4090\n",
      "Epoch 177/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 1.2612e-05 - accuracy: 0.4090\n",
      "Epoch 178/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 1.0439e-04 - accuracy: 0.4090\n",
      "Epoch 179/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 1.2588e-05 - accuracy: 0.4090\n",
      "Epoch 180/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 1.5171e-05 - accuracy: 0.4090\n",
      "Epoch 181/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 2.2501e-05 - accuracy: 0.4090\n",
      "Epoch 182/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 2.3416e-05 - accuracy: 0.4090\n",
      "Epoch 183/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 2.0005e-04 - accuracy: 0.4090\n",
      "Epoch 184/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 5.0878e-04 - accuracy: 0.4089\n",
      "Epoch 185/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 8.0161e-05 - accuracy: 0.4090\n",
      "Epoch 186/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 3.0916e-05 - accuracy: 0.4090\n",
      "Epoch 187/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 1.0937e-05 - accuracy: 0.4090\n",
      "Epoch 188/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 6.8955e-06 - accuracy: 0.4090\n",
      "Epoch 189/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 4.6256e-06 - accuracy: 0.4090\n",
      "Epoch 190/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 5.7304e-06 - accuracy: 0.4090\n",
      "Epoch 191/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 1.5516e-05 - accuracy: 0.4090\n",
      "Epoch 192/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 9.1865e-06 - accuracy: 0.4090\n",
      "Epoch 193/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 5.6647e-06 - accuracy: 0.4090\n",
      "Epoch 194/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 5.6666e-06 - accuracy: 0.4090\n",
      "Epoch 195/500\n",
      "439/439 [==============================] - 5s 11ms/step - loss: 5.3275e-06 - accuracy: 0.4090\n",
      "Epoch 196/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 1.5398e-04 - accuracy: 0.4090\n",
      "Epoch 197/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 5.4741e-04 - accuracy: 0.4089\n",
      "Epoch 198/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 2.6370e-04 - accuracy: 0.4090\n",
      "Epoch 199/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 5.8749e-05 - accuracy: 0.4090\n",
      "Epoch 200/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 8.2106e-06 - accuracy: 0.4090\n",
      "Epoch 201/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 6.5289e-06 - accuracy: 0.4090\n",
      "Epoch 202/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 1.7456e-05 - accuracy: 0.4090\n",
      "Epoch 203/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 7.2273e-06 - accuracy: 0.4090\n",
      "Epoch 204/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 1.6729e-05 - accuracy: 0.4090\n",
      "Epoch 205/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 1.7136e-05 - accuracy: 0.4090\n",
      "Epoch 206/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 2.0691e-05 - accuracy: 0.4090\n",
      "Epoch 207/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 1.7568e-05 - accuracy: 0.4090\n",
      "Epoch 208/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 2.6319e-04 - accuracy: 0.4090\n",
      "Epoch 209/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 1.7309e-04 - accuracy: 0.4090\n",
      "Epoch 210/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 4.9321e-05 - accuracy: 0.4090\n",
      "Epoch 211/500\n",
      "439/439 [==============================] - 5s 11ms/step - loss: 3.8314e-05 - accuracy: 0.4090\n",
      "Epoch 212/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 5.4886e-06 - accuracy: 0.4090\n",
      "Epoch 213/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 1.0994e-05 - accuracy: 0.4090\n",
      "Epoch 214/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 7.1520e-06 - accuracy: 0.4090\n",
      "Epoch 215/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 5.8249e-06 - accuracy: 0.4090\n",
      "Epoch 216/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 6.5326e-06 - accuracy: 0.4090\n",
      "Epoch 217/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 6.9600e-06 - accuracy: 0.4090\n",
      "Epoch 218/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 6.8198e-06 - accuracy: 0.4090\n",
      "Epoch 219/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 6.6497e-06 - accuracy: 0.4090\n",
      "Epoch 220/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 4.2602e-06 - accuracy: 0.4090\n",
      "Epoch 221/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 1.0970e-04 - accuracy: 0.4090\n",
      "Epoch 222/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 1.8608e-04 - accuracy: 0.4090\n",
      "Epoch 223/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 5.1656e-04 - accuracy: 0.4090\n",
      "Epoch 224/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 3.2539e-04 - accuracy: 0.4090\n",
      "Epoch 225/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 6.7401e-05 - accuracy: 0.4090\n",
      "Epoch 226/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 2.6859e-05 - accuracy: 0.4090\n",
      "Epoch 227/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 1.6958e-05 - accuracy: 0.4090\n",
      "Epoch 228/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 4.5208e-06 - accuracy: 0.4090\n",
      "Epoch 229/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 4.8821e-06 - accuracy: 0.4090\n",
      "Epoch 230/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 1.8202e-05 - accuracy: 0.4090\n",
      "Epoch 231/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 7.5741e-06 - accuracy: 0.4090\n",
      "Epoch 232/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 7.9625e-06 - accuracy: 0.4090\n",
      "Epoch 233/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 4.9933e-06 - accuracy: 0.4090\n",
      "Epoch 234/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 9.3973e-06 - accuracy: 0.4090\n",
      "Epoch 235/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 1.6618e-05 - accuracy: 0.4090\n",
      "Epoch 236/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 2.5677e-04 - accuracy: 0.4090\n",
      "Epoch 237/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 2.2490e-04 - accuracy: 0.4090\n",
      "Epoch 238/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 2.3598e-04 - accuracy: 0.4090\n",
      "Epoch 239/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 7.6102e-05 - accuracy: 0.4090\n",
      "Epoch 240/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 1.3897e-05 - accuracy: 0.4090\n",
      "Epoch 241/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 6.9804e-06 - accuracy: 0.4090\n",
      "Epoch 242/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 5.8713e-06 - accuracy: 0.4090\n",
      "Epoch 243/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 7.0125e-06 - accuracy: 0.4090\n",
      "Epoch 244/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 6.1326e-06 - accuracy: 0.4090\n",
      "Epoch 245/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 5.8758e-06 - accuracy: 0.4090\n",
      "Epoch 246/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 6.0691e-06 - accuracy: 0.4090\n",
      "Epoch 247/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 7.7322e-06 - accuracy: 0.4090\n",
      "Epoch 248/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 6.1611e-06 - accuracy: 0.4090\n",
      "Epoch 249/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 1.2861e-05 - accuracy: 0.4090\n",
      "Epoch 250/500\n",
      "439/439 [==============================] - ETA: 0s - loss: 7.5906e-06 - accuracy: 0.4090Model saved at epoch: 250\n",
      "439/439 [==============================] - 7s 16ms/step - loss: 7.5906e-06 - accuracy: 0.4090\n",
      "Epoch 251/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 3.2483e-04 - accuracy: 0.4090\n",
      "Epoch 252/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 1.3041e-04 - accuracy: 0.4090\n",
      "Epoch 253/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 4.4935e-05 - accuracy: 0.4090\n",
      "Epoch 254/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 1.8407e-05 - accuracy: 0.4090\n",
      "Epoch 255/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 7.4356e-06 - accuracy: 0.4090\n",
      "Epoch 256/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 9.3633e-06 - accuracy: 0.4090\n",
      "Epoch 257/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 1.2314e-04 - accuracy: 0.4090\n",
      "Epoch 258/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 1.9500e-04 - accuracy: 0.4090\n",
      "Epoch 259/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 2.6806e-05 - accuracy: 0.4090\n",
      "Epoch 260/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 1.0887e-05 - accuracy: 0.4090\n",
      "Epoch 261/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 4.6721e-06 - accuracy: 0.4090\n",
      "Epoch 262/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 3.2968e-06 - accuracy: 0.4090\n",
      "Epoch 263/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 3.8458e-06 - accuracy: 0.4090\n",
      "Epoch 264/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 2.5356e-06 - accuracy: 0.4090\n",
      "Epoch 265/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 2.8691e-06 - accuracy: 0.4090\n",
      "Epoch 266/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 3.8422e-04 - accuracy: 0.4090\n",
      "Epoch 267/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 1.1627e-04 - accuracy: 0.4090\n",
      "Epoch 268/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 2.5777e-05 - accuracy: 0.4090\n",
      "Epoch 269/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 1.8538e-04 - accuracy: 0.4090\n",
      "Epoch 270/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 3.0211e-05 - accuracy: 0.4090\n",
      "Epoch 271/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 1.4644e-04 - accuracy: 0.4090\n",
      "Epoch 272/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 1.1224e-04 - accuracy: 0.4090\n",
      "Epoch 273/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 6.0457e-06 - accuracy: 0.4090\n",
      "Epoch 274/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 2.5603e-06 - accuracy: 0.4090\n",
      "Epoch 275/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 3.2640e-07 - accuracy: 0.4090\n",
      "Epoch 276/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 3.3333e-07 - accuracy: 0.4090\n",
      "Epoch 277/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 3.4107e-07 - accuracy: 0.4090\n",
      "Epoch 278/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 1.6407e-07 - accuracy: 0.4090\n",
      "Epoch 279/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 1.4691e-07 - accuracy: 0.4090\n",
      "Epoch 280/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 5.3512e-08 - accuracy: 0.4090\n",
      "Epoch 281/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 4.5797e-05 - accuracy: 0.4090\n",
      "Epoch 282/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 8.6051e-05 - accuracy: 0.4090\n",
      "Epoch 283/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 1.4027e-04 - accuracy: 0.4090\n",
      "Epoch 284/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 3.6504e-05 - accuracy: 0.4090\n",
      "Epoch 285/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 8.3636e-05 - accuracy: 0.4090\n",
      "Epoch 286/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 1.2064e-05 - accuracy: 0.4090\n",
      "Epoch 287/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 2.5058e-05 - accuracy: 0.4090\n",
      "Epoch 288/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 7.4687e-07 - accuracy: 0.4090\n",
      "Epoch 289/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 2.4391e-07 - accuracy: 0.4090\n",
      "Epoch 290/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 2.2419e-07 - accuracy: 0.4090\n",
      "Epoch 291/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 1.4286e-07 - accuracy: 0.4090\n",
      "Epoch 292/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 7.6981e-08 - accuracy: 0.4090\n",
      "Epoch 293/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 6.5741e-08 - accuracy: 0.4090\n",
      "Epoch 294/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 7.2700e-08 - accuracy: 0.4090\n",
      "Epoch 295/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 4.8227e-08 - accuracy: 0.4090\n",
      "Epoch 296/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 1.0240e-07 - accuracy: 0.4090\n",
      "Epoch 297/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 1.3713e-07 - accuracy: 0.4090\n",
      "Epoch 298/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 2.9596e-08 - accuracy: 0.4090\n",
      "Epoch 299/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 1.1497e-08 - accuracy: 0.4090\n",
      "Epoch 300/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 6.0609e-09 - accuracy: 0.4090\n",
      "Epoch 301/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 4.5855e-09 - accuracy: 0.4090\n",
      "Epoch 302/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 3.6587e-09 - accuracy: 0.4090\n",
      "Epoch 303/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 3.4920e-09 - accuracy: 0.4090\n",
      "Epoch 304/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 2.7382e-09 - accuracy: 0.4090\n",
      "Epoch 305/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 1.8821e-09 - accuracy: 0.4090\n",
      "Epoch 306/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 4.3892e-09 - accuracy: 0.4090\n",
      "Epoch 307/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 4.8975e-09 - accuracy: 0.4090\n",
      "Epoch 308/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 1.8544e-09 - accuracy: 0.4090\n",
      "Epoch 309/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 7.5357e-10 - accuracy: 0.4090\n",
      "Epoch 310/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 1.1531e-09 - accuracy: 0.4090\n",
      "Epoch 311/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 1.9747e-09 - accuracy: 0.4090\n",
      "Epoch 312/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 6.5586e-10 - accuracy: 0.4090\n",
      "Epoch 313/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 2.5403e-09 - accuracy: 0.4090\n",
      "Epoch 314/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 3.8458e-10 - accuracy: 0.4090\n",
      "Epoch 315/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 5.7018e-10 - accuracy: 0.4090\n",
      "Epoch 316/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 2.9520e-10 - accuracy: 0.4090\n",
      "Epoch 317/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 9.0669e-10 - accuracy: 0.4090\n",
      "Epoch 318/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 7.4468e-09 - accuracy: 0.4090\n",
      "Epoch 319/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 3.3666e-10 - accuracy: 0.4090\n",
      "Epoch 320/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 2.6517e-10 - accuracy: 0.4090\n",
      "Epoch 321/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 5.7218e-11 - accuracy: 0.4090\n",
      "Epoch 322/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 9.1270e-10 - accuracy: 0.4090\n",
      "Epoch 323/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 6.8341e-11 - accuracy: 0.4090\n",
      "Epoch 324/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 3.9854e-11 - accuracy: 0.4090\n",
      "Epoch 325/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 1.6715e-10 - accuracy: 0.4090\n",
      "Epoch 326/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 5.0305e-11 - accuracy: 0.4090\n",
      "Epoch 327/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 6.6862e-11 - accuracy: 0.4090\n",
      "Epoch 328/500\n",
      "439/439 [==============================] - 6s 13ms/step - loss: 2.4896e-11 - accuracy: 0.4090\n",
      "Epoch 329/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 8.0428e-11 - accuracy: 0.4090\n",
      "Epoch 330/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 3.4138e-11 - accuracy: 0.4090\n",
      "Epoch 331/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 3.9002e-11 - accuracy: 0.4090\n",
      "Epoch 332/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 3.1923e-11 - accuracy: 0.4090\n",
      "Epoch 333/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 1.5104e-11 - accuracy: 0.4090\n",
      "Epoch 334/500\n",
      "439/439 [==============================] - 6s 13ms/step - loss: 2.2072e-10 - accuracy: 0.4090\n",
      "Epoch 335/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 1.8780e-11 - accuracy: 0.4090\n",
      "Epoch 336/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 2.9728e-11 - accuracy: 0.4090\n",
      "Epoch 337/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 3.2518e-11 - accuracy: 0.4090\n",
      "Epoch 338/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 5.4453e-11 - accuracy: 0.4090\n",
      "Epoch 339/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 1.6534e-11 - accuracy: 0.4090\n",
      "Epoch 340/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 3.4710e-11 - accuracy: 0.4090\n",
      "Epoch 341/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 4.4755e-10 - accuracy: 0.4090\n",
      "Epoch 342/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 6.7342e-10 - accuracy: 0.4090\n",
      "Epoch 343/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 2.0502e-10 - accuracy: 0.4090\n",
      "Epoch 344/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 1.4594e-11 - accuracy: 0.4090\n",
      "Epoch 345/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 2.5117e-11 - accuracy: 0.4090\n",
      "Epoch 346/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 4.3627e-12 - accuracy: 0.4090\n",
      "Epoch 347/500\n",
      "439/439 [==============================] - 10s 23ms/step - loss: 2.8161e-11 - accuracy: 0.4090\n",
      "Epoch 348/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 2.4076e-11 - accuracy: 0.4090\n",
      "Epoch 349/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 3.5810e-12 - accuracy: 0.4090\n",
      "Epoch 350/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 5.8710e-11 - accuracy: 0.4090\n",
      "Epoch 351/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 1.0032e-11 - accuracy: 0.4090\n",
      "Epoch 352/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 3.2182e-10 - accuracy: 0.4090\n",
      "Epoch 353/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 5.5232e-10 - accuracy: 0.4090\n",
      "Epoch 354/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 7.2057e-11 - accuracy: 0.4090\n",
      "Epoch 355/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 7.3382e-12 - accuracy: 0.4090\n",
      "Epoch 356/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 4.2750e-12 - accuracy: 0.4090\n",
      "Epoch 357/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 1.1685e-11 - accuracy: 0.4090\n",
      "Epoch 358/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 3.1492e-11 - accuracy: 0.4090\n",
      "Epoch 359/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 1.5836e-11 - accuracy: 0.4090\n",
      "Epoch 360/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 1.7551e-11 - accuracy: 0.4090\n",
      "Epoch 361/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 1.6140e-11 - accuracy: 0.4090\n",
      "Epoch 362/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 3.2306e-12 - accuracy: 0.4090\n",
      "Epoch 363/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 5.4275e-10 - accuracy: 0.4090\n",
      "Epoch 364/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 3.4575e-12 - accuracy: 0.4090\n",
      "Epoch 365/500\n",
      "439/439 [==============================] - 6s 13ms/step - loss: 2.9722e-12 - accuracy: 0.4090\n",
      "Epoch 366/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 2.8135e-12 - accuracy: 0.4090\n",
      "Epoch 367/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 6.7647e-12 - accuracy: 0.4090\n",
      "Epoch 368/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 4.7864e-12 - accuracy: 0.4090\n",
      "Epoch 369/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 7.1669e-12 - accuracy: 0.4090\n",
      "Epoch 370/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 5.6579e-08 - accuracy: 0.4090\n",
      "Epoch 371/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 0.0010 - accuracy: 0.4089\n",
      "Epoch 372/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 1.1975e-04 - accuracy: 0.4090\n",
      "Epoch 373/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 1.1186e-05 - accuracy: 0.4090\n",
      "Epoch 374/500\n",
      "439/439 [==============================] - 6s 13ms/step - loss: 1.3322e-06 - accuracy: 0.4090\n",
      "Epoch 375/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 5.3551e-07 - accuracy: 0.4090\n",
      "Epoch 376/500\n",
      "439/439 [==============================] - 6s 14ms/step - loss: 5.5772e-07 - accuracy: 0.4090\n",
      "Epoch 377/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 1.6812e-07 - accuracy: 0.4090\n",
      "Epoch 378/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 7.3946e-08 - accuracy: 0.4090\n",
      "Epoch 379/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 1.1259e-07 - accuracy: 0.4090\n",
      "Epoch 380/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 3.4022e-07 - accuracy: 0.4090\n",
      "Epoch 381/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 8.2456e-07 - accuracy: 0.4090\n",
      "Epoch 382/500\n",
      "439/439 [==============================] - 6s 13ms/step - loss: 9.8470e-07 - accuracy: 0.4090\n",
      "Epoch 383/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 5.7900e-05 - accuracy: 0.4090\n",
      "Epoch 384/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 2.4814e-04 - accuracy: 0.4090\n",
      "Epoch 385/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 2.0646e-04 - accuracy: 0.4090\n",
      "Epoch 386/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 6.2379e-05 - accuracy: 0.4090\n",
      "Epoch 387/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 3.0480e-05 - accuracy: 0.4090\n",
      "Epoch 388/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 1.5516e-05 - accuracy: 0.4090\n",
      "Epoch 389/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 9.1001e-06 - accuracy: 0.4090\n",
      "Epoch 390/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 2.1848e-06 - accuracy: 0.4090\n",
      "Epoch 391/500\n",
      "439/439 [==============================] - 6s 13ms/step - loss: 2.5437e-07 - accuracy: 0.4090\n",
      "Epoch 392/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 5.1553e-07 - accuracy: 0.4090\n",
      "Epoch 393/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 7.2193e-08 - accuracy: 0.4090\n",
      "Epoch 394/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 4.9009e-08 - accuracy: 0.4090\n",
      "Epoch 395/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 3.3375e-08 - accuracy: 0.4090\n",
      "Epoch 396/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 6.7247e-08 - accuracy: 0.4090\n",
      "Epoch 397/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 1.9576e-08 - accuracy: 0.4090\n",
      "Epoch 398/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 1.5117e-08 - accuracy: 0.4090\n",
      "Epoch 399/500\n",
      "439/439 [==============================] - 6s 13ms/step - loss: 7.5909e-09 - accuracy: 0.4090\n",
      "Epoch 400/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 5.6953e-09 - accuracy: 0.4090\n",
      "Epoch 401/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 1.0663e-08 - accuracy: 0.4090\n",
      "Epoch 402/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 1.4728e-08 - accuracy: 0.4090\n",
      "Epoch 403/500\n",
      "439/439 [==============================] - 6s 13ms/step - loss: 2.3747e-08 - accuracy: 0.4090\n",
      "Epoch 404/500\n",
      "439/439 [==============================] - 6s 14ms/step - loss: 2.2719e-08 - accuracy: 0.4090\n",
      "Epoch 405/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 3.8211e-09 - accuracy: 0.4090\n",
      "Epoch 406/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 2.9810e-09 - accuracy: 0.4090\n",
      "Epoch 407/500\n",
      "439/439 [==============================] - 6s 13ms/step - loss: 2.3514e-09 - accuracy: 0.4090\n",
      "Epoch 408/500\n",
      "439/439 [==============================] - 6s 15ms/step - loss: 9.4182e-09 - accuracy: 0.4090\n",
      "Epoch 409/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 9.8183e-10 - accuracy: 0.4090\n",
      "Epoch 410/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 1.4211e-09 - accuracy: 0.4090\n",
      "Epoch 411/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 6.5165e-10 - accuracy: 0.4090\n",
      "Epoch 412/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 1.4666e-09 - accuracy: 0.4090\n",
      "Epoch 413/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 1.2611e-09 - accuracy: 0.4090\n",
      "Epoch 414/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 1.8459e-09 - accuracy: 0.4090\n",
      "Epoch 415/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 7.7517e-10 - accuracy: 0.4090\n",
      "Epoch 416/500\n",
      "439/439 [==============================] - 6s 13ms/step - loss: 1.1374e-09 - accuracy: 0.4090\n",
      "Epoch 417/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 4.6528e-10 - accuracy: 0.4090\n",
      "Epoch 418/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 6.6735e-10 - accuracy: 0.4090\n",
      "Epoch 419/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 3.6034e-10 - accuracy: 0.4090\n",
      "Epoch 420/500\n",
      "439/439 [==============================] - 6s 13ms/step - loss: 4.8176e-10 - accuracy: 0.4090\n",
      "Epoch 421/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 1.8959e-10 - accuracy: 0.4090\n",
      "Epoch 422/500\n",
      "439/439 [==============================] - 6s 13ms/step - loss: 2.3463e-10 - accuracy: 0.4090\n",
      "Epoch 423/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 3.6167e-10 - accuracy: 0.4090\n",
      "Epoch 424/500\n",
      "439/439 [==============================] - 6s 13ms/step - loss: 2.8841e-10 - accuracy: 0.4090\n",
      "Epoch 425/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 3.2553e-10 - accuracy: 0.4090\n",
      "Epoch 426/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 5.2244e-10 - accuracy: 0.4090\n",
      "Epoch 427/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 1.5842e-10 - accuracy: 0.4090\n",
      "Epoch 428/500\n",
      "439/439 [==============================] - 6s 13ms/step - loss: 1.8759e-10 - accuracy: 0.4090\n",
      "Epoch 429/500\n",
      "439/439 [==============================] - 5s 13ms/step - loss: 2.7233e-10 - accuracy: 0.4090\n",
      "Epoch 430/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 7.8960e-10 - accuracy: 0.4090\n",
      "Epoch 431/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 1.2451e-10 - accuracy: 0.4090\n",
      "Epoch 432/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 4.5210e-11 - accuracy: 0.4090\n",
      "Epoch 433/500\n",
      "439/439 [==============================] - 6s 13ms/step - loss: 1.5037e-11 - accuracy: 0.4090\n",
      "Epoch 434/500\n",
      "439/439 [==============================] - 6s 13ms/step - loss: 1.6634e-10 - accuracy: 0.4090\n",
      "Epoch 435/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 2.1543e-11 - accuracy: 0.4090\n",
      "Epoch 436/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 2.8073e-11 - accuracy: 0.4090\n",
      "Epoch 437/500\n",
      "439/439 [==============================] - 8s 18ms/step - loss: 5.6655e-11 - accuracy: 0.4090\n",
      "Epoch 438/500\n",
      "439/439 [==============================] - 6s 13ms/step - loss: 8.8459e-11 - accuracy: 0.4090\n",
      "Epoch 439/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 1.3462e-10 - accuracy: 0.4090\n",
      "Epoch 440/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 1.7641e-04 - accuracy: 0.4090\n",
      "Epoch 441/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 4.0784e-04 - accuracy: 0.4090\n",
      "Epoch 442/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 3.0289e-05 - accuracy: 0.4090\n",
      "Epoch 443/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 1.5506e-06 - accuracy: 0.4090\n",
      "Epoch 444/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 3.6306e-06 - accuracy: 0.4090\n",
      "Epoch 445/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 2.0844e-06 - accuracy: 0.4090\n",
      "Epoch 446/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 4.5388e-07 - accuracy: 0.4090\n",
      "Epoch 447/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 1.6583e-07 - accuracy: 0.4090\n",
      "Epoch 448/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 9.1558e-08 - accuracy: 0.4090\n",
      "Epoch 449/500\n",
      "439/439 [==============================] - 6s 14ms/step - loss: 7.1820e-08 - accuracy: 0.4090\n",
      "Epoch 450/500\n",
      "439/439 [==============================] - 6s 13ms/step - loss: 1.0628e-07 - accuracy: 0.4090\n",
      "Epoch 451/500\n",
      "439/439 [==============================] - 6s 13ms/step - loss: 1.4704e-07 - accuracy: 0.4090\n",
      "Epoch 452/500\n",
      "439/439 [==============================] - 6s 13ms/step - loss: 4.3190e-08 - accuracy: 0.4090\n",
      "Epoch 453/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 5.1870e-08 - accuracy: 0.4090\n",
      "Epoch 454/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 5.1276e-08 - accuracy: 0.4090\n",
      "Epoch 455/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 6.6785e-08 - accuracy: 0.4090\n",
      "Epoch 456/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 3.9710e-08 - accuracy: 0.4090\n",
      "Epoch 457/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 2.0168e-08 - accuracy: 0.4090\n",
      "Epoch 458/500\n",
      "439/439 [==============================] - 6s 13ms/step - loss: 1.0638e-08 - accuracy: 0.4090\n",
      "Epoch 459/500\n",
      "439/439 [==============================] - 7s 15ms/step - loss: 8.2887e-09 - accuracy: 0.4090\n",
      "Epoch 460/500\n",
      "439/439 [==============================] - 7s 15ms/step - loss: 7.7815e-09 - accuracy: 0.4090\n",
      "Epoch 461/500\n",
      "439/439 [==============================] - 7s 17ms/step - loss: 3.6231e-09 - accuracy: 0.4090\n",
      "Epoch 462/500\n",
      "439/439 [==============================] - 6s 15ms/step - loss: 4.9048e-09 - accuracy: 0.4090\n",
      "Epoch 463/500\n",
      "439/439 [==============================] - 6s 13ms/step - loss: 2.2440e-09 - accuracy: 0.4090\n",
      "Epoch 464/500\n",
      "439/439 [==============================] - 6s 14ms/step - loss: 6.2115e-09 - accuracy: 0.4090\n",
      "Epoch 465/500\n",
      "439/439 [==============================] - 7s 15ms/step - loss: 2.1135e-09 - accuracy: 0.4090\n",
      "Epoch 466/500\n",
      "439/439 [==============================] - 6s 14ms/step - loss: 3.7855e-09 - accuracy: 0.4090\n",
      "Epoch 467/500\n",
      "439/439 [==============================] - 5s 13ms/step - loss: 2.1177e-09 - accuracy: 0.4090\n",
      "Epoch 468/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 9.7272e-10 - accuracy: 0.4090\n",
      "Epoch 469/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 1.0141e-09 - accuracy: 0.4090\n",
      "Epoch 470/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 1.4818e-09 - accuracy: 0.4090\n",
      "Epoch 471/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 1.0297e-09 - accuracy: 0.4090\n",
      "Epoch 472/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 5.5363e-10 - accuracy: 0.4090\n",
      "Epoch 473/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 6.9996e-10 - accuracy: 0.4090\n",
      "Epoch 474/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 7.8976e-10 - accuracy: 0.4090\n",
      "Epoch 475/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 2.6953e-10 - accuracy: 0.4090\n",
      "Epoch 476/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 2.5123e-10 - accuracy: 0.4090\n",
      "Epoch 477/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 2.2566e-10 - accuracy: 0.4090\n",
      "Epoch 478/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 5.0391e-10 - accuracy: 0.4090\n",
      "Epoch 479/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 4.4850e-10 - accuracy: 0.4090\n",
      "Epoch 480/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 2.2956e-10 - accuracy: 0.4090\n",
      "Epoch 481/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 5.3583e-10 - accuracy: 0.4090\n",
      "Epoch 482/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 2.2686e-10 - accuracy: 0.4090\n",
      "Epoch 483/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 1.0152e-09 - accuracy: 0.4090\n",
      "Epoch 484/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 7.9645e-06 - accuracy: 0.4090\n",
      "Epoch 485/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 5.9035e-04 - accuracy: 0.4090\n",
      "Epoch 486/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 2.8955e-04 - accuracy: 0.4090\n",
      "Epoch 487/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 1.0323e-04 - accuracy: 0.4090\n",
      "Epoch 488/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 2.5434e-05 - accuracy: 0.4090\n",
      "Epoch 489/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 4.9241e-06 - accuracy: 0.4090\n",
      "Epoch 490/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 6.5413e-07 - accuracy: 0.4090\n",
      "Epoch 491/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 3.3775e-07 - accuracy: 0.4090\n",
      "Epoch 492/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 1.9193e-07 - accuracy: 0.4090\n",
      "Epoch 493/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 2.1724e-07 - accuracy: 0.4090\n",
      "Epoch 494/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 9.0924e-08 - accuracy: 0.4090\n",
      "Epoch 495/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 1.0895e-07 - accuracy: 0.4090\n",
      "Epoch 496/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 1.2085e-07 - accuracy: 0.4090\n",
      "Epoch 497/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 4.5581e-08 - accuracy: 0.4090\n",
      "Epoch 498/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 3.2219e-08 - accuracy: 0.4090\n",
      "Epoch 499/500\n",
      "439/439 [==============================] - 5s 12ms/step - loss: 3.0483e-08 - accuracy: 0.4090\n",
      "Epoch 500/500\n",
      "439/439 [==============================] - ETA: 0s - loss: 3.2262e-08 - accuracy: 0.4090Model saved at epoch: 500\n",
      "439/439 [==============================] - 7s 15ms/step - loss: 3.2262e-08 - accuracy: 0.4090\n",
      "time: 45min 8s (started: 2023-10-23 09:30:53 -04:00)\n"
     ]
    }
   ],
   "source": [
    "class CustomSaveModel(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, save_freq):\n",
    "        super(CustomSaveModel, self).__init__()\n",
    "        self.save_freq = save_freq\n",
    "    \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if (epoch + 1) % self.save_freq == 0:\n",
    "            save_path = f\"ner_saved_{epoch + 1}_20231023\"\n",
    "            self.model.save(save_path)\n",
    "            print(f\"Model saved at epoch: {epoch + 1}\")\n",
    "\n",
    "if train == 'Y':\n",
    "    save_callback = CustomSaveModel(save_freq=250)\n",
    "    ner_model.fit(train_dataset, epochs=500, callbacks=[save_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "64434797-ee23-460a-93e0-835c84eebc7b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[  988 10950   204   628     6  3938   215  5773    26  1036     0     1\n",
      "      0     0]], shape=(1, 14), dtype=int64)\n",
      "1/1 [==============================] - 0s 106ms/step\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'B-PER', 'O', 'O', 'O']\n",
      "time: 182 ms (started: 2023-10-23 13:45:29 -04:00)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def tokenize_and_convert_to_ids(text):\n",
    "    tokens = text.split()\n",
    "    return lowercase_and_convert_to_ids(tokens)\n",
    "\n",
    "\n",
    "# Sample inference using the trained model\n",
    "sample_input = tokenize_and_convert_to_ids(\n",
    "    \"eu rejects german call to boycott british lamb from Steve parson the funky Parson\"\n",
    ")\n",
    "sample_input = tf.reshape(sample_input, shape=[1, -1])\n",
    "print(sample_input)\n",
    "\n",
    "output = ner_model.predict(sample_input)\n",
    "prediction = np.argmax(output, axis=-1)[0]\n",
    "prediction = [mapping[i] for i in prediction]\n",
    "\n",
    "# eu -> B-ORG, german -> B-MISC, british -> B-MISC\n",
    "print(prediction)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "82f4f220-2bb8-46a3-9cf2-4ea8643b2853",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 116ms/step\n",
      "1/1 [==============================] - 0s 90ms/step\n",
      "1/1 [==============================] - 0s 89ms/step\n",
      "1/1 [==============================] - 0s 87ms/step\n",
      "1/1 [==============================] - 0s 91ms/step\n",
      "1/1 [==============================] - 0s 86ms/step\n",
      "1/1 [==============================] - 0s 89ms/step\n",
      "1/1 [==============================] - 0s 91ms/step\n",
      "1/1 [==============================] - 0s 85ms/step\n",
      "1/1 [==============================] - 0s 89ms/step\n",
      "1/1 [==============================] - 0s 83ms/step\n",
      "1/1 [==============================] - 0s 80ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 84ms/step\n",
      "1/1 [==============================] - 0s 95ms/step\n",
      "1/1 [==============================] - 0s 90ms/step\n",
      "1/1 [==============================] - 0s 95ms/step\n",
      "1/1 [==============================] - 0s 85ms/step\n",
      "1/1 [==============================] - 0s 88ms/step\n",
      "1/1 [==============================] - 0s 88ms/step\n",
      "1/1 [==============================] - 0s 83ms/step\n",
      "1/1 [==============================] - 0s 87ms/step\n",
      "1/1 [==============================] - 0s 83ms/step\n",
      "1/1 [==============================] - 0s 89ms/step\n",
      "1/1 [==============================] - 0s 88ms/step\n",
      "1/1 [==============================] - 0s 93ms/step\n",
      "1/1 [==============================] - 0s 92ms/step\n",
      "1/1 [==============================] - 0s 83ms/step\n",
      "1/1 [==============================] - 0s 86ms/step\n",
      "1/1 [==============================] - 0s 85ms/step\n",
      "1/1 [==============================] - 0s 82ms/step\n",
      "1/1 [==============================] - 0s 88ms/step\n",
      "1/1 [==============================] - 0s 91ms/step\n",
      "1/1 [==============================] - 0s 90ms/step\n",
      "1/1 [==============================] - 0s 83ms/step\n",
      "1/1 [==============================] - 0s 82ms/step\n",
      "1/1 [==============================] - 0s 84ms/step\n",
      "1/1 [==============================] - 0s 82ms/step\n",
      "1/1 [==============================] - 0s 86ms/step\n",
      "1/1 [==============================] - 0s 84ms/step\n",
      "1/1 [==============================] - 0s 85ms/step\n",
      "1/1 [==============================] - 0s 85ms/step\n",
      "1/1 [==============================] - 0s 89ms/step\n",
      "1/1 [==============================] - 0s 92ms/step\n",
      "1/1 [==============================] - 0s 84ms/step\n",
      "1/1 [==============================] - 0s 88ms/step\n",
      "1/1 [==============================] - 0s 83ms/step\n",
      "1/1 [==============================] - 0s 85ms/step\n",
      "1/1 [==============================] - 0s 86ms/step\n",
      "1/1 [==============================] - 0s 83ms/step\n",
      "1/1 [==============================] - 0s 87ms/step\n",
      "1/1 [==============================] - 0s 88ms/step\n",
      "1/1 [==============================] - 0s 86ms/step\n",
      "1/1 [==============================] - 0s 84ms/step\n",
      "1/1 [==============================] - 0s 83ms/step\n",
      "1/1 [==============================] - 0s 91ms/step\n",
      "1/1 [==============================] - 0s 86ms/step\n",
      "1/1 [==============================] - 0s 87ms/step\n",
      "1/1 [==============================] - 0s 83ms/step\n",
      "1/1 [==============================] - 0s 83ms/step\n",
      "1/1 [==============================] - 0s 85ms/step\n",
      "1/1 [==============================] - 0s 95ms/step\n",
      "1/1 [==============================] - 0s 90ms/step\n",
      "1/1 [==============================] - 0s 86ms/step\n",
      "1/1 [==============================] - 0s 87ms/step\n",
      "1/1 [==============================] - 0s 99ms/step\n",
      "1/1 [==============================] - 0s 95ms/step\n",
      "1/1 [==============================] - 0s 96ms/step\n",
      "1/1 [==============================] - 0s 84ms/step\n",
      "1/1 [==============================] - 0s 88ms/step\n",
      "1/1 [==============================] - 0s 86ms/step\n",
      "1/1 [==============================] - 0s 84ms/step\n",
      "1/1 [==============================] - 0s 83ms/step\n",
      "1/1 [==============================] - 0s 85ms/step\n",
      "1/1 [==============================] - 0s 87ms/step\n",
      "1/1 [==============================] - 0s 84ms/step\n",
      "1/1 [==============================] - 0s 88ms/step\n",
      "1/1 [==============================] - 0s 86ms/step\n",
      "1/1 [==============================] - 0s 86ms/step\n",
      "1/1 [==============================] - 0s 88ms/step\n",
      "1/1 [==============================] - 0s 84ms/step\n",
      "1/1 [==============================] - 0s 88ms/step\n",
      "1/1 [==============================] - 0s 85ms/step\n",
      "1/1 [==============================] - 0s 84ms/step\n",
      "1/1 [==============================] - 0s 85ms/step\n",
      "1/1 [==============================] - 0s 84ms/step\n",
      "1/1 [==============================] - 0s 90ms/step\n",
      "1/1 [==============================] - 0s 86ms/step\n",
      "1/1 [==============================] - 0s 86ms/step\n",
      "1/1 [==============================] - 0s 86ms/step\n",
      "1/1 [==============================] - 0s 86ms/step\n",
      "1/1 [==============================] - 0s 88ms/step\n",
      "1/1 [==============================] - 0s 84ms/step\n",
      "1/1 [==============================] - 0s 89ms/step\n",
      "1/1 [==============================] - 0s 85ms/step\n",
      "1/1 [==============================] - 0s 84ms/step\n",
      "1/1 [==============================] - 0s 85ms/step\n",
      "1/1 [==============================] - 0s 84ms/step\n",
      "1/1 [==============================] - 0s 89ms/step\n",
      "1/1 [==============================] - 0s 85ms/step\n",
      "1/1 [==============================] - 0s 86ms/step\n",
      "1/1 [==============================] - 0s 86ms/step\n",
      "processed 51362 tokens with 3149 phrases; found: 2685 phrases; correct: 2344.\n",
      "accuracy:  74.44%; (non-O)\n",
      "accuracy:  97.77%; precision:  87.30%; recall:  74.44%; FB1:  80.36\n",
      "              PER: precision:  87.30%; recall:  74.44%; FB1:  80.36  2685\n",
      "time: 13 s (started: 2023-10-23 12:55:37 -04:00)\n"
     ]
    }
   ],
   "source": [
    "def calculate_metrics(dataset):\n",
    "    all_true_tag_ids, all_predicted_tag_ids = [], []\n",
    "\n",
    "    for x, y in dataset:\n",
    "        output = ner_model.predict(x)\n",
    "        predictions = np.argmax(output, axis=-1)\n",
    "        predictions = np.reshape(predictions, [-1])\n",
    "\n",
    "        true_tag_ids = np.reshape(y, [-1])\n",
    "\n",
    "        mask = (true_tag_ids > 0) & (predictions > 0)\n",
    "        true_tag_ids = true_tag_ids[mask]\n",
    "        predicted_tag_ids = predictions[mask]\n",
    "\n",
    "        all_true_tag_ids.append(true_tag_ids)\n",
    "        all_predicted_tag_ids.append(predicted_tag_ids)\n",
    "\n",
    "    all_true_tag_ids = np.concatenate(all_true_tag_ids)\n",
    "    all_predicted_tag_ids = np.concatenate(all_predicted_tag_ids)\n",
    "\n",
    "    predicted_tags = [mapping[tag] for tag in all_predicted_tag_ids]\n",
    "    real_tags = [mapping[tag] for tag in all_true_tag_ids]\n",
    "\n",
    "    evaluate(real_tags, predicted_tags)\n",
    "\n",
    "\n",
    "calculate_metrics(val_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b940f3f-0c55-4edd-bf5c-51e55c70470b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
